参考来源:
作者：ShowMeAI
链接：https://juejin.cn/post/7073122495431180324
来源：稀土掘金
1.机器学习概述

  1.1什么是机器学习
  (人工智能目的是使计算机能够模拟人的思维方式和行为)
  机器学习是人工智能的子集，是实现人工智能的一种途径，但却不是唯一的途径。深度学习(Deep learning)是机器学习的子集，灵感来自人脑。
  国外知名学者对机器学习的定义:
  机器学习研究的是计算机怎样模拟人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构，使之不断改善自身。

  1.2机器学习的三要素
  机器学习三要素包括数据(data)、模型(model)、算法(algorithm)。
    1.2.1数据
    数据驱动：数据驱动指的是我们基于客观的量化数据，通过主动数据的采集分析以支持决策。与之相对的是经验驱动，比如我们常说的「拍脑袋」。
    1.2.2模型&算法
    模型：在AI数据驱动的范畴内，模型指的是基于数据X做决策Y的假设函数，可以有不同的形态，计算型和规则型等。
    算法：指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。通常是一个最优化的问题。

  1.3机器学习发展历程
  人工智能一词最早出现于1956年，用于探索一些问题的有效解决方案。1960年，美国国防部借助「神经网络」这一概念，训练计算机模仿人类的推理过程。
  2010年之前，谷歌、微软等科技巨头改进了机器学习算法，将查询的准确度提升到了新的高度。而后，随着数据量的增加、先进的算法、计算和存储容量的提高，机器学习得到了更进一步的发展。

  1.4机器学习核心技术
  分类：应用以分类数据进行模型训练，根据模型对新样本进行精准分类与预测。
  聚类：从海量数据中识别数据的相似性与差异性，并按照最大共同点聚合为多个类别。
  异常检测：对数据点的分布规律进行分析，识别与正常数据及差异较大的离群点。
  回归：根据对已知属性值数据的训练，为模型寻找最佳拟合参数，基于模型预测新样本的输出值。

  1.5机器学习基本流程
  机器学习工作流（WorkFlow）包含数据预处理（Processing）、模型学习（Learning）、模型评估（Evaluation）、新样本预测（Prediction）几个步骤。
  数据预处理：输入（未处理的数据 + 标签）→处理过程（特征处理+幅度缩放、特征选择、维度约减、采样）→输出（测试集 + 训练集）。
  模型学习：模型选择、交叉验证、结果评估、超参选择。
  模型评估：了解模型对于数据集测试的得分。
  新样本预测：预测测试集。

  1.6机器学习应用场景
  作为一套数据驱动的方法，机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别和机器人等领域。
  智能医疗：智能假肢、外骨骼、医疗保健机器人、手术机器人、智能健康管理等。
  人脸识别：门禁系统、考勤系统、人脸识别防盗门、电子护照及身份证，还可以利用人脸识别系统和网络，在全国范围内搜捕逃犯。
  机器人的控制领域：工业机器人、机械臂、多足机器人、扫地机器人、无人机等。

2.机器学习基本名词
  监督学习（Supervised Learning）：训练集有标记信息，学习方式有分类和回归。
  无监督学习（Unsupervised Learning）：训练集没有标记信息，学习方式有聚类和降维。
  强化学习（Reinforcement Learning）：有延迟和稀疏的反馈标签的学习方式。
  示例/样本：上面一条数据集中的一条数据。
  属性/特征：「色泽」「根蒂」等。
  属性空间/样本空间/输入空间X：由全部属性张成的空间。
  特征向量：空间中每个点对应的一个坐标向量。
  标记：关于示例结果的信息，如（（色泽=青绿，根蒂=蜷缩，敲声=浊响），好瓜），其中「好瓜」称为标记。
  分类：若要预测的是离散值，如「好瓜」，「坏瓜」，此类学习任务称为分类。
  假设：学得模型对应了关于数据的某种潜在规律。
  真相：潜在规律自身。
  学习过程：是为了找出或逼近真相。
  泛化能力：学得模型适用于新样本的能力。一般来说，训练样本越大，越有可能通过学习来获得具有强泛化能力的模型。

3.机器学习算法分类

  3.1机器学习算法依托的问题场景
  机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动「学习」的算法。
  机器学习算法从数据中自动分析获得规律，并利用规律对未知数据进行预测。机器学习理论关注可以实现的、行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。
  机器学习最主要的类别有：监督学习、无监督学习和强化学习。
  监督学习：从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。
  无监督学习：与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有生成对抗网络（GAN）、聚类。
  强化学习：通过观察来学习做成如何的动作。每个动作都会对环境有所影响，学习对象根据观察到的周围环境的反馈来做出判断。

  3.2分类问题
  分类问题是机器学习非常重要的一个组成部分。它的目标是根据已知样本的某些特征，判断一个新的样本属于哪种已知的样本类。分类问题可以细分如下：
  二分类问题：表示分类任务中有两个类别新的样本属于哪种已知的样本类。
  多类分类（Multiclass classification）问题：表示分类任务中有多类别。
  多标签分类（Multilabel classification）问题：给每个样本一系列的目标标签。

  3.3回归问题

  3.4聚类问题

  3.5降维问题

4.机器学习模型评估与选择

  4.1机器学习与数据拟合
  机器学习最典型的监督学习为分类与回归问题。分类问题中，我们学习出来一条「决策边界」完成数据区分；在回归问题中，我们学习出拟合样本分布的曲线。
  4.2训练集与数据集
  我们以房价预估为例，讲述一下涉及的概念。
  训练集（Training Set）：帮助训练模型，简单的说就是通过训练集的数据让确定拟合曲线的参数。
  测试集（Test Set）：为了测试已经训练好的模型的精确度。
  当然，test set这并不能保证模型的正确性，只是说相似的数据用此模型会得出相似的结果。因为在训练模型的时候，参数全是根据现有训练集里的数据进行修正、拟合，有可能会出现过拟合的情况，即这个参数仅对训练集里的数据拟合比较准确，这个时候再有一个数据需要利用模型预测结果，准确率可能就会很差。

  4.3经验误差
  在训练集的数据上进行学习。模型在训练集上的误差称为「经验误差」（Empirical Error）。但是经验误差并不是越小越好，因为我们希望在新的没有见过的数据上，也能有好的预估结果。

  4.4过拟合
  过拟合，指的是模型在训练集上表现的很好，但是在交叉验证集合测试集上表现一般，也就是说模型对未知样本的预测表现一般，泛化（Generalization）能力较差。
  如何防止过拟合呢？一般的方法有Early Stopping、数据集扩增（Data Augmentation）、正则化、Dropout等。

  4.5偏差
  偏差（Bias），它通常指的是模型拟合的偏差程度。给定无数套训练集而期望拟合出来的模型就是平均模型。偏差就是真实模型和平均模型的差异。
  简单模型是一组直线，平均之后得到的平均模型是一条直的虚线，与真实模型曲线的差别较大（灰色阴影部分较大）。因此，简单模型通常高偏差 。
  复杂模型是一组起伏很大波浪线，平均之后最大值和最小组都会相互抵消，和真实模型的曲线差别较小，因此复杂模型通常低偏差。

  4.6方差
  方差（Variance），它通常指的是模型的平稳程度（简单程度）。简单模型的对应的函数如出一辙，都是水平直线，而且平均模型的函数也是一条水平直线，因此简单模型的方差很小，并且对数据的变动不敏感。
  复杂模型的对应的函数千奇百怪，毫无任何规则，但平均模型的函数也是一条平滑的曲线，因此复杂模型的方差很大，并且对数据的变动很敏感。

  4.7偏差与方差的平衡

  4.8性能度量指标
  性能度量是衡量模型泛化能力的数值评价标准，反映了当前问题（任务需求）。使用不同的性能度量可能会导致不同的评判结果。

    4.8.1回归问题
    关于模型「好坏」的判断，不仅取决于算法和数据，还取决于当前任务需求。回归问题常用的性能度量指标有：平均绝对误差、均方误差、均方根误差、R平方等。

    4.8.2分类问题
    分类问题常用的性能度量指标包括错误率（Error Rate）、精确率（Accuracy）、查准率（Precision）、查全率（Recall）、F1、ROC曲线、AUC曲线和R平方等。

  4.9评估方法
  我们手上没有未知的样本，如何可靠地评估？关键是要获得可靠的「测试集数据」（Test Set），即测试集（用于评估）应该与训练集（用于模型学习）「互斥」。
  常见的评估方法有：留出法（Hold-out）、交叉验证法（ Cross Validation）、自助（Bootstrap）。

  4.10模型调优与选择准则
  我们希望找到对当前问题表达能力好，且模型复杂度较低的模型：
  表达力好的模型，可以较好地对训练数据中的规律和模式进行学习；
  复杂度低的模型，方差较小，不容易过拟合，有较好的泛化表达。

  4.11如何选择最优的模型

    4.11.1验证集评估选择
    切分数据为训练集和验证集。
    对于准备好的候选超参数，在训练集上进行模型，在验证集上评估。

    4.11.2网格搜索/随机搜索交叉验证
    通过网格搜索/随机搜索产出候选的超参数组。
    对参数组的每一组超参数，使用交叉验证评估效果。
    选出效果最好的超参数。

    4.11.3贝叶斯优化
    基于贝叶斯优化的超参数调优。
  
  
  
